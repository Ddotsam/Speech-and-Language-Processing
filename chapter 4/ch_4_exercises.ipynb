{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0ef45b6-3592-4337-8a23-30bfb0ca5c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af57c7db-4258-4172-946b-9f307198d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_data = {\n",
    "    'sentence': ['fun couple love love', \n",
    "                 'fast furious shoot', \n",
    "                 'couple fly fast fun fun', \n",
    "                 'furious shoot shoot fun', \n",
    "                 'fly fast shoot love',\n",
    "                ],\n",
    "    'class': ['comedy',\n",
    "              'action',\n",
    "              'comedy', \n",
    "              'action',\n",
    "              'action',\n",
    "             ]\n",
    "    \n",
    "}\n",
    "q2_train = pd.DataFrame(q2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d10ddde7-79bf-425d-a4bc-031f046f90d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateClassProbs(train_df):\n",
    "    class_counts = {}\n",
    "    for class_name in train_df['class']:\n",
    "        if not class_name in class_counts:\n",
    "            class_counts[class_name] = 0\n",
    "        class_counts[class_name] += 1\n",
    "    class_probs = {name: math.log(count / len(train_df['class'])) for name, count in class_counts.items()}\n",
    "    return class_probs\n",
    "\n",
    "def generateUniqueWordsByDoc(train_df):\n",
    "    unique_words_by_doc = {class_name: list() for class_name in train_df['class']}\n",
    "    for index in range(len(train_df)):\n",
    "        gold_class = train_df['class'][index]\n",
    "        unique_words_by_doc[gold_class].append(set(train_df['sentence'][index].split()))\n",
    "    return unique_words_by_doc\n",
    "\n",
    "def generateBinarizedCounts(train_df, uniq_words_doc):\n",
    "    binarized_counts = {key: dict() for key in uniq_words_doc.keys()}\n",
    "    for key in uniq_words_doc.keys():\n",
    "        list_of_words = uniq_words_doc[key]\n",
    "        for word_set in list_of_words:\n",
    "            for word in word_set:\n",
    "                if not word in binarized_counts[key]:\n",
    "                    binarized_counts[key][word] = 0\n",
    "                binarized_counts[key][word] += 1\n",
    "    return binarized_counts\n",
    "\n",
    "def getVocabularySize(bin_counts):\n",
    "    class_vocab_size = {}\n",
    "    for classification in bin_counts.keys():\n",
    "        class_vocab_size[classification] = 0\n",
    "        for count in bin_counts[classification].values():\n",
    "            class_vocab_size[classification] += count\n",
    "            \n",
    "    return class_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3c7b5d1-7c95-4440-9a72-b4dd41dad4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nieveBays(document, train_df):\n",
    "    class_probs = generateClassProbs(train_df)\n",
    "    unique_words_by_doc = generateUniqueWordsByDoc(train_df)\n",
    "    binarized_counts = generateBinarizedCounts(train_df, unique_words_by_doc)\n",
    "    vocab_size_by_class = getVocabularySize(binarized_counts)\n",
    "\n",
    "    new_tok = document.split()\n",
    "    vocab_size = len(new_tok)\n",
    "    post_probs = {key: 0 for key in binarized_counts.keys()}\n",
    "    for classification in post_probs.keys():\n",
    "        probs_list = []\n",
    "        for word in new_tok:\n",
    "            if word in binarized_counts[classification]:\n",
    "                probs_list.append(math.log(1+1)-math.log(vocab_size+vocab_size_by_class[classification]))\n",
    "            else:\n",
    "                probs_list.append(-1*math.log(vocab_size+vocab_size_by_class[classification]))\n",
    "        post_probs[classification] = sum(probs_list) + class_probs[classification]\n",
    "    \n",
    "    return  (max(post_probs, key=post_probs.get), post_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "639ed2b2-2bbd-4f15-b115-d4cf29d51052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is action.\n",
      "The log posterier probabilities are: {'comedy': -8.006784147535463, 'action': -6.9081718588673535}.\n"
     ]
    }
   ],
   "source": [
    "new_doc = 'fast couple shoot fly'\n",
    "predicted_class, log_posterier_probs = nieveBays(new_doc, q2_data)\n",
    "print(f'The predicted class is {predicted_class}.\\nThe log posterier probabilities are: {log_posterier_probs}.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
